{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "sys.path.append(\"kaggle/input/neurips-open-polymer-prediction-2025\")\n",
    "base_path = \"kaggle/input/neurips-open-polymer-prediction-2025/\"\n",
    "supplement_path = \"kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/\"\n",
    "tc_smiles_path = \"kaggle/input/tc-smiles/\"\n",
    "smiles_extra_data_path = \"kaggle/input/smiles-extra-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import optuna\n",
    "import wandb\n",
    "\n",
    "from data_preparation import load_qm9_dataset\n",
    "from train import pretrain_qm9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QM9(130831)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import QM9\n",
    "\n",
    "dataset = QM9(root=\"data/qm9\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training on cuda\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# ç¯å¢ƒè®¾ç½®\n",
    "# -----------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"âœ… Training on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# æ•°æ®åŠ è½½\n",
    "# -----------------------------\n",
    "loader, dataset = load_qm9_dataset(root=\"data/qm9\", batch_size=1024)\n",
    "n = len(dataset)\n",
    "train_set, val_set = random_split(dataset, [int(0.9*n), n - int(0.9*n)])\n",
    "train_loader = DataLoader(train_set, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Optuna ç›®æ ‡å‡½æ•°\n",
    "# -----------------------------\n",
    "def objective(trial):\n",
    "    ckpt_path = f\"checkpoints/trial_{trial.number}_best.pt\"\n",
    "    model, hist = pretrain_qm9(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        dataset=dataset,\n",
    "        hidden_dim=trial.suggest_categorical(\"hidden_dim\", [128, 256, 512]),\n",
    "        lr=trial.suggest_loguniform(\"lr\", 1e-4, 1e-2),\n",
    "        num_edge_layers=trial.suggest_int(\"num_edge_layers\", 2, 16),\n",
    "        dropout=trial.suggest_float(\"dropout\", 0.0, 0.3),\n",
    "        epochs=20,\n",
    "        device=device,\n",
    "        run_wandb=False,\n",
    "        ckpt_path=ckpt_path\n",
    "    )\n",
    "    return min(hist[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "storage_path = \"sqlite:///optuna_qm9.db\"  # ä¿å­˜åœ¨å½“å‰ç›®å½•\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"qm9_pretrain\",\n",
    "    storage=storage_path,\n",
    "    load_if_exists=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Device: cuda | Params: 19.05M | Tasks: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/20] Train 5039.177, Val 2012.391 | mu:1.049 | alpha:4.661 | homo:0.481 | lumo:0.880 | gap:0.921 | r2:189.494 | zpve:0.476 | U0:435.961 | U:435.010 | H:451.903 | G:468.354 | Cv:2.669 | u0_atom:5.312 | u_atom:4.575 | h_atom:4.816 | g_atom:4.345 | A:0.904 | B:0.339 | C:0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/20] Train 2823.700, Val 1994.852 | mu:1.084 | alpha:5.112 | homo:0.756 | lumo:0.767 | gap:0.908 | r2:190.129 | zpve:0.627 | U0:381.626 | U:501.141 | H:481.400 | G:395.035 | Cv:2.982 | u0_atom:8.802 | u_atom:7.113 | h_atom:8.060 | g_atom:7.843 | A:0.929 | B:0.322 | C:0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/20] Train 2720.030, Val 2239.258 | mu:0.960 | alpha:3.908 | homo:0.528 | lumo:0.663 | gap:0.821 | r2:163.404 | zpve:0.420 | U0:476.142 | U:457.036 | H:503.516 | G:614.772 | Cv:2.144 | u0_atom:3.104 | u_atom:3.520 | h_atom:3.853 | g_atom:3.053 | A:0.897 | B:0.306 | C:0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/20] Train 2710.695, Val 2000.603 | mu:0.952 | alpha:3.827 | homo:0.758 | lumo:0.619 | gap:0.689 | r2:153.537 | zpve:0.312 | U0:433.255 | U:510.246 | H:495.418 | G:379.490 | Cv:2.226 | u0_atom:4.168 | u_atom:3.446 | h_atom:4.578 | g_atom:5.644 | A:0.935 | B:0.303 | C:0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/20] Train 2692.143, Val 2128.938 | mu:1.005 | alpha:3.518 | homo:0.857 | lumo:0.573 | gap:0.790 | r2:150.297 | zpve:0.309 | U0:524.510 | U:516.226 | H:442.858 | G:466.570 | Cv:2.045 | u0_atom:4.521 | u_atom:3.992 | h_atom:3.902 | g_atom:5.496 | A:0.970 | B:0.305 | C:0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/20] Train 2686.393, Val 1709.517 | mu:0.961 | alpha:3.159 | homo:0.523 | lumo:0.553 | gap:0.731 | r2:144.567 | zpve:0.312 | U0:486.084 | U:353.167 | H:349.155 | G:353.462 | Cv:1.975 | u0_atom:3.512 | u_atom:4.273 | h_atom:3.030 | g_atom:2.704 | A:0.878 | B:0.288 | C:0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/20] Train 2688.092, Val 1890.278 | mu:0.927 | alpha:3.210 | homo:0.605 | lumo:0.578 | gap:0.658 | r2:148.575 | zpve:0.240 | U0:358.021 | U:515.839 | H:454.839 | G:392.660 | Cv:1.785 | u0_atom:2.616 | u_atom:2.624 | h_atom:3.116 | g_atom:2.598 | A:0.880 | B:0.295 | C:0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/20] Train 2680.722, Val 1712.158 | mu:0.913 | alpha:3.387 | homo:0.574 | lumo:0.610 | gap:0.807 | r2:145.859 | zpve:0.298 | U0:440.979 | U:354.160 | H:374.204 | G:371.557 | Cv:1.769 | u0_atom:5.135 | u_atom:3.722 | h_atom:4.044 | g_atom:2.784 | A:0.882 | B:0.292 | C:0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/20] Train 2674.557, Val 1793.320 | mu:0.957 | alpha:3.742 | homo:0.362 | lumo:0.607 | gap:0.835 | r2:147.047 | zpve:0.179 | U0:417.342 | U:348.891 | H:354.708 | G:501.976 | Cv:2.438 | u0_atom:4.213 | u_atom:3.281 | h_atom:2.844 | g_atom:2.530 | A:0.861 | B:0.312 | C:0.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/20] Train 2668.026, Val 2058.296 | mu:0.941 | alpha:3.133 | homo:0.368 | lumo:0.513 | gap:0.648 | r2:157.066 | zpve:0.359 | U0:489.679 | U:495.757 | H:453.833 | G:440.164 | Cv:1.979 | u0_atom:2.816 | u_atom:3.224 | h_atom:3.562 | g_atom:2.933 | A:0.856 | B:0.283 | C:0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-09-08 01:42:12,732] Trial 0 failed with parameters: {'hidden_dim': 2048, 'num_edge_layers': 5, 'dropout': 0.08739049662913614, 'lr': 0.0033953307338137396} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/tmp/pbs.206459.stdct-mgmt-02/ipykernel_3890535/2582930910.py\", line 10, in objective\n",
      "    _, hist = pretrain_qm9(\n",
      "  File \"/nfs/home/svu/e1350261/kaggle/kaggle-neurips-0907/train.py\", line 157, in pretrain_qm9\n",
      "    history = fit(model, train_loader, val_loader, optimizer, device, tasks,\n",
      "  File \"/nfs/home/svu/e1350261/kaggle/kaggle-neurips-0907/train.py\", line 105, in fit\n",
      "    tr_loss, tr_mae = train_one_epoch(model, train_loader, optimizer, device, tasks, use_mask, epoch, epochs)\n",
      "  File \"/nfs/home/svu/e1350261/kaggle/kaggle-neurips-0907/train.py\", line 25, in train_one_epoch\n",
      "    outputs = model(batch)\n",
      "  File \"/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/nfs/home/svu/e1350261/kaggle/kaggle-neurips-0907/model.py\", line 181, in forward\n",
      "    g = self.encoder(data.x, data.edge_index, data.edge_attr, data.batch, edge_weight=edge_weight)\n",
      "  File \"/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/nfs/home/svu/e1350261/kaggle/kaggle-neurips-0907/model.py\", line 108, in forward\n",
      "    graph_repr = global_mean_pool(node_hidden, batch)\n",
      "  File \"/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/torch_geometric/nn/pool/glob.py\", line 63, in global_mean_pool\n",
      "    return scatter(x, batch, dim=dim, dim_size=size, reduce='mean')\n",
      "  File \"/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/torch_geometric/utils/_scatter.py\", line 53, in scatter\n",
      "    dim_size = int(index.max()) + 1 if index.numel() > 0 else 0\n",
      "KeyboardInterrupt\n",
      "[W 2025-09-08 01:42:12,740] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# -----------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# è¿è¡Œè¶…å‚æœç´¢\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# -----------------------------\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mâœ… æœ€ä¼˜è¶…å‚æ•°:\u001b[39m\u001b[39m\"\u001b[39m, study\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mparams)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mğŸ“‰ æœ€ä¼˜éªŒè¯é›† loss:\u001b[39m\u001b[39m\"\u001b[39m, study\u001b[39m.\u001b[39mbest_value)\n",
      "File \u001b[0;32m/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     _optimize(\n\u001b[1;32m    491\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    492\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    493\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    494\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    495\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    496\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    497\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    498\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    499\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    500\u001b[0m     )\n",
      "File \u001b[0;32m/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[1;32m     64\u001b[0m             study,\n\u001b[1;32m     65\u001b[0m             func,\n\u001b[1;32m     66\u001b[0m             n_trials,\n\u001b[1;32m     67\u001b[0m             timeout,\n\u001b[1;32m     68\u001b[0m             catch,\n\u001b[1;32m     69\u001b[0m             callbacks,\n\u001b[1;32m     70\u001b[0m             gc_after_trial,\n\u001b[1;32m     71\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     72\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     73\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial_id \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/optuna/study/_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     updated_state \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    255\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    259\u001b[0m \u001b[39mreturn\u001b[39;00m trial\u001b[39m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    202\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      7\u001b[0m dropout \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m\"\u001b[39m\u001b[39mdropout\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.3\u001b[39m)\n\u001b[1;32m      8\u001b[0m lr \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1e-4\u001b[39m, \u001b[39m1e-2\u001b[39m, log\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m _, hist \u001b[39m=\u001b[39m pretrain_qm9(\n\u001b[1;32m     11\u001b[0m     train_loader\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[1;32m     12\u001b[0m     val_loader\u001b[39m=\u001b[39;49mval_loader,\n\u001b[1;32m     13\u001b[0m     dataset\u001b[39m=\u001b[39;49mdataset,\n\u001b[1;32m     14\u001b[0m     hidden_dim\u001b[39m=\u001b[39;49mhidden_dim,\n\u001b[1;32m     15\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m     16\u001b[0m     num_edge_layers\u001b[39m=\u001b[39;49mnum_edge_layers,\n\u001b[1;32m     17\u001b[0m     dropout\u001b[39m=\u001b[39;49mdropout,\n\u001b[1;32m     18\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m     19\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     20\u001b[0m     run_wandb\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     21\u001b[0m     print_all_tasks\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m hist[\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/nfs/home/svu/e1350261/kaggle/kaggle-neurips-0907/train.py:157\u001b[0m, in \u001b[0;36mpretrain_qm9\u001b[0;34m(hidden_dim, lr, epochs, device, num_edge_layers, dropout, run_wandb, train_loader, val_loader, dataset, print_all_tasks)\u001b[0m\n\u001b[1;32m    145\u001b[0m model \u001b[39m=\u001b[39m WDMPNNModel(\n\u001b[1;32m    146\u001b[0m     node_feat_dim\u001b[39m=\u001b[39mnode_dim,\n\u001b[1;32m    147\u001b[0m     edge_feat_dim\u001b[39m=\u001b[39medge_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m     dropout\u001b[39m=\u001b[39mdropout\n\u001b[1;32m    153\u001b[0m )\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    155\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr)\n\u001b[0;32m--> 157\u001b[0m history \u001b[39m=\u001b[39m fit(model, train_loader, val_loader, optimizer, device, tasks,\n\u001b[1;32m    158\u001b[0m               epochs\u001b[39m=\u001b[39;49mepochs, use_mask\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, run_wandb\u001b[39m=\u001b[39;49mrun_wandb,\n\u001b[1;32m    159\u001b[0m               project\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mqm9-pretrain\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    160\u001b[0m               print_all_tasks\u001b[39m=\u001b[39;49mprint_all_tasks)\n\u001b[1;32m    162\u001b[0m \u001b[39mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m/nfs/home/svu/e1350261/kaggle/kaggle-neurips-0907/train.py:105\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, train_loader, val_loader, optimizer, device, tasks, epochs, use_mask, patience, run_wandb, project, print_all_tasks)\u001b[0m\n\u001b[1;32m    102\u001b[0m best_val, patience_counter \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minf\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m0\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m--> 105\u001b[0m     tr_loss, tr_mae \u001b[39m=\u001b[39m train_one_epoch(model, train_loader, optimizer, device, tasks, use_mask, epoch, epochs)\n\u001b[1;32m    106\u001b[0m     val_loss, val_mae \u001b[39m=\u001b[39m evaluate(model, val_loader, device, tasks, use_mask, epoch, epochs)\n\u001b[1;32m    108\u001b[0m     history[\u001b[39m\"\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(tr_loss)\n",
      "File \u001b[0;32m/nfs/home/svu/e1350261/kaggle/kaggle-neurips-0907/train.py:25\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, optimizer, device, tasks, use_mask, epoch, epochs)\u001b[0m\n\u001b[1;32m     23\u001b[0m batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     24\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 25\u001b[0m outputs \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(batch, \u001b[39m\"\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m use_mask:\n\u001b[1;32m     28\u001b[0m     mask \u001b[39m=\u001b[39m {t: batch\u001b[39m.\u001b[39mmask[:, i] \u001b[39mfor\u001b[39;00m i, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tasks)}\n",
      "File \u001b[0;32m/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/nfs/home/svu/e1350261/kaggle/kaggle-neurips-0907/model.py:181\u001b[0m, in \u001b[0;36mWDMPNNModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, data) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[torch\u001b[39m.\u001b[39mTensor, Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]]:\n\u001b[1;32m    180\u001b[0m     edge_weight \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(data, \u001b[39m\"\u001b[39m\u001b[39medge_weight\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 181\u001b[0m     g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(data\u001b[39m.\u001b[39;49mx, data\u001b[39m.\u001b[39;49medge_index, data\u001b[39m.\u001b[39;49medge_attr, data\u001b[39m.\u001b[39;49mbatch, edge_weight\u001b[39m=\u001b[39;49medge_weight)\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead(g)\n",
      "File \u001b[0;32m/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/nfs/home/svu/e1350261/kaggle/kaggle-neurips-0907/model.py:108\u001b[0m, in \u001b[0;36mWDMPNNEncoder.forward\u001b[0;34m(self, x, edge_index, edge_attr, batch, edge_weight)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39m# pooling\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 108\u001b[0m     graph_repr \u001b[39m=\u001b[39m global_mean_pool(node_hidden, batch)\n\u001b[1;32m    109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     graph_repr \u001b[39m=\u001b[39m global_add_pool(node_hidden, batch)\n",
      "File \u001b[0;32m/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/torch_geometric/nn/pool/glob.py:63\u001b[0m, in \u001b[0;36mglobal_mean_pool\u001b[0;34m(x, batch, size)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mif\u001b[39;00m batch \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39mdim, keepdim\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mdim() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m scatter(x, batch, dim\u001b[39m=\u001b[39;49mdim, dim_size\u001b[39m=\u001b[39;49msize, reduce\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/scratch/e1350261/venvs/ai39/lib64/python3.9/site-packages/torch_geometric/utils/_scatter.py:53\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe `dim` argument must lay between 0 and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msrc\u001b[39m.\u001b[39mdim()\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m (got \u001b[39m\u001b[39m{\u001b[39;00mdim\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[39mif\u001b[39;00m dim_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 53\u001b[0m     dim_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(index\u001b[39m.\u001b[39;49mmax()) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mnumel() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[39m# For now, we maintain various different code paths, based on whether\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# the input requires gradients and whether it lays on the CPU/GPU.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# For example, `torch_scatter` is usually faster than\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39m# indices, but is therefore way slower in its backward implementation.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m# More insights can be found in `test/utils/test_scatter.py`.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m size \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39msize()[:dim] \u001b[39m+\u001b[39m (dim_size, ) \u001b[39m+\u001b[39m src\u001b[39m.\u001b[39msize()[dim \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m:]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# è¿è¡Œè¶…å‚æœç´¢\n",
    "# -----------------------------\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"âœ… æœ€ä¼˜è¶…å‚æ•°:\", study.best_trial.params)\n",
    "print(\"ğŸ“‰ æœ€ä¼˜éªŒè¯é›† loss:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (ai39)",
   "language": "python",
   "name": "ai39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86715117325bb669dcee076931360a6797c084140656b2fef4bf943c7ad69ff7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
